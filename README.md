
- üëÄ I‚Äôm interested in consulting on your next Data Engineering, Data Architecture or Data Governance project
- üå± I‚Äôm currently studying Machine Learning.
- üíûÔ∏è I‚Äôm looking to collaborate on Python projects. 
- üì´ How to reach me: <b> hire@remote-data-engineering.com </b>

With significant experience as a Senior Analyst, Data Quality Engineer, Data Architect and Data Engineer, I believe my skillset is an excellent match for your organization.

In my previous <b> Senior Data Engineer </b> roles, I worked extensively with Microsoft tools such as <b>Azure Data Factory</b>, <b>Azure SQL </b>, <b>Azure Databricks</b>, <b>Azure Synapse Analytics</b> and <b>Azure DevOps</b>. I was responsible for orchestrating bulk copy pipelines within Azure Data Factory, championing standard operating procedures for moving artifacts through <b>CI/CD pipelines</b>, and designing, validating and scripting stored procedures that loaded Fact and Dim tables into Azure SQL in under 5 minutes, 100% validated for data accuracy and completeness, with documentation. Furthermore, I built reliable roadmaps in Azure DevOps for addressing vague technical problems, creating <b>Data Models</b> and <b>Analytical Reports</b> with complex Dax Tables, Measures, and Columns for enterprise-wide route reporting utilizing <b>Power BI</b>.

In my <b> Data Quality Engineer </b>  and <b> Data Governance </b> roles, I set up a data estate for hardware engineering information systems in <b>Microsoft Purview</b>, and I built a proof of concept by populating databases in Azure SQL and Azure Synapse Analytics. Additionally, I created <b>Python</b> scripts for <b>Exploratory Data Analysis</b> of <b>Machine Learning</b> datasets, worked with SMEs to scan databases, set up schedules in Purview, and deleted items in Purview using <b>REST APIs</b>. Updating tasks for Sprint Planning and maintaining code in repos were also a part of my responsibilities as a data quality engineer at Microsoft.

In my hospital roles, I have earned certifications in Cerner and Epic Clarity, re-written Transact SQL reports into <b> Spark SQL with Databricks </b>, created dependable <b> Tabular Data Models</b> from Clarity data to simplify Surgical Reporting, in addition to troubleshooting optimized canned Epic Crystal and Webi reports for faster run times.

The <a href = "https://github.com/RemoteDataEngineer/FlDogs/tree/main"> latest project </a> in my Github is a <a href = "https://github.com/RemoteDataEngineer/FlDogs/blob/main/PetfinderApi%20FlDogs%20Production%2020230731.pbix"> Power Bi </a> containing data from the Petfinder API, <b>Upserted</b> weekly into a <b> Delta Lake </b>, populated by a Data Architecture that includes an <b>Azure Logic App</b>, <b>Azure Data Factory</b> and <b> <a href = "https://github.com/RemoteDataEngineer/FlDogs/tree/main/Databricks%20Notebooks/PetFinderApi%20-%20Repo"> Databricks Notebooks </a> </b> coded in <b>PySpark</b> and <b>Spark SQL</b>. 

Overall, my experience will enable me to drive efficiency, create formal processes, design and develop data architecture, build reliable roadmaps, and optimize reports using various tools and technologies for your organization.

I am excited about the prospect of joining your team and I look forward to contributing towards the company's success. 
